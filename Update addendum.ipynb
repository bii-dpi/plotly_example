{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly update 010521: addendum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "\n",
    "from os import listdir\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objs as go, offline\n",
    "from plotly.express.colors import qualitative\n",
    "\n",
    "# Allow figures to work in HTML-exported version of notebook.\n",
    "offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation results\n",
    "\n",
    "Training and validation results regarding:\n",
    "\n",
    "1. Accuracy\n",
    "2. Recall\n",
    "3. Precision\n",
    "4. AUC\n",
    "5. AUPR\n",
    "6. Binary cross entropy loss\n",
    "\n",
    "are read in and plotted here, so comparisons can be made between folds and between training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for reading in CSVs and plotting.\n",
    "PREFIXES = [\"cv_1\", \"cv_2\", \"cv_3\", \"single\"]\n",
    "FOLDS = [\"CV 1\", \"CV 2\", \"CV 3\", \"Single\"]\n",
    "FOLD_COLORS = dict(zip(FOLDS, qualitative.D3[:4]))\n",
    "\n",
    "TRAINING_RESULTS_HEADER = [\n",
    "    \"Accuracy\",\n",
    "    \"Recall\",\n",
    "    \"Precision\",\n",
    "    \"AUC\",\n",
    "    \"AUPR\",\n",
    "    \"BCE Loss\",\n",
    "    \"roce_1\",\n",
    "    \"roce_2\",\n",
    "    \"roce_3\",\n",
    "    \"roce_4\",\n",
    "]\n",
    "VALIDATION_RESULTS_HEADER = [\"Epoch\"] + TRAINING_RESULTS_HEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read and compile CSVs.\n",
    "\n",
    "\n",
    "def get_train_perf(prefix):\n",
    "    \"\"\"Return DataFrame of the specified fold's training performance.\"\"\"\n",
    "    curr_train_perf = pd.read_csv(\n",
    "        f\"train_test_stats/{prefix}_train_results.csv\",\n",
    "        header=None,\n",
    "        names=TRAINING_RESULTS_HEADER,\n",
    "    )\n",
    "    curr_train_perf[\"Epoch\"] = range(1, 31)\n",
    "    curr_train_perf[\"Fold\"] = (\n",
    "        prefix.capitalize() if prefix == \"single\" else prefix.upper().replace(\"_\", \" \")\n",
    "    )\n",
    "    return curr_train_perf\n",
    "\n",
    "\n",
    "def get_val_perf(prefix):\n",
    "    \"\"\"Return DataFrame of the specified fold's validation performance.\"\"\"\n",
    "    curr_val_perf = pd.read_csv(\n",
    "        f\"train_test_stats/{prefix}_test_results.csv\",\n",
    "        header=None,\n",
    "        names=VALIDATION_RESULTS_HEADER,\n",
    "    )\n",
    "    curr_val_perf[\"Fold\"] = (\n",
    "        prefix.capitalize() if prefix == \"single\" else prefix.upper().replace(\"_\", \" \")\n",
    "    )\n",
    "    return curr_val_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_perf = pd.concat(\n",
    "    [get_train_perf(prefix) for prefix in PREFIXES[:-1]],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "all_val_perf = pd.concat(\n",
    "    [get_val_perf(prefix) for prefix in PREFIXES],\n",
    "    ignore_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_perf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_perf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More details on the validation schemes\n",
    "\n",
    "Recall there are two validation schemes: the single validation scheme that uses the same proteins for training and validation, and the three-fold cross validation based on using data from three disjoint clusters of proteins, created to maxmize the difference between each cluster's proteins. More details on the exact nature of the clustering can be found in [Ragoze et al., 2017](https://pubmed.ncbi.nlm.nih.gov/28368587/).\n",
    "\n",
    "*The proteins*\n",
    "\n",
    "There are 102 proteins. The three clusters, and the validation folds they represent, are:\n",
    "\n",
    "<table>\n",
    "    <tr><th><center>CV 1</center></th><th><center>CV 2</center></th><th><center>CV 3</center></th></tr>\n",
    "<tr><td>\n",
    "\n",
    "| Name | Description |\n",
    "|-:|:-|\n",
    "| ABL1 | Tyrosine-protein kinase ABL |\n",
    "| AKT1 | Serine/threonine-protein kinase AKT |\n",
    "| AKT2 | Serine/threonine-protein kinase AKT2 |\n",
    "| BRAF | Serine/threonine-protein kinase B-raf |\n",
    "| CDK2 | Cyclin-dependent kinase 2 |\n",
    "| CSF1R | Macrophage colony stimulating factor receptor |\n",
    "| EGFR | Epidermal growth factor receptor erbB1 |\n",
    "| FABP4 | Fatty acid binding protein adipocyte |\n",
    "| FAK1 | Focal adhesion kinase 1 |\n",
    "| FGFR1 | Fibroblast growth factor receptor 1 |\n",
    "| GRIA2 | Glutamate receptor ionotropic, AMPA 2 |\n",
    "| GRIK1 | Glutamate receptor ionotropic kainate 1 |\n",
    "| HS90A | Heat shock protein HSP 90-alpha |\n",
    "| IGF1R | Insulin-like growth factor I receptor |\n",
    "| ITAL | Leukocyte adhesion glycoprotein LFA-1 alpha |\n",
    "| JAK2 | Tyrosine-protein kinase JAK2 |\n",
    "| KIF11 | Kinesin-like protein 1 |\n",
    "| KIT | Stem cell growth factor receptor |\n",
    "| KPCB | Protein kinase C beta |\n",
    "| LCK | Tyrosine-protein kinase LCK |\n",
    "| MAPK2 | MAP kinase-activated protein kinase 2 |\n",
    "| MET | Hepatocyte growth factor receptor |\n",
    "| MK01 | MAP kinase ERK2 |\n",
    "| MK10 | c-Jun N-terminal kinase 3 |\n",
    "| MK14 | MAP kinase p38 alpha |\n",
    "| MP2K1 | Dual specificity mitogen-activated protein kinase kinase 1 |\n",
    "| PLK1 | Serine/threonine-protein kinase PLK1 |\n",
    "| ROCK1 | Rho-associated protein kinase 1 |\n",
    "| SRC | Tyrosine-protein kinase SRC |\n",
    "| TGFR1 | TGF-beta receptor type I |\n",
    "| VGFR2 | Vascular endothelial growth factor receptor 2 |\n",
    "| WEE1 | Serine/threonine-protein kinase WEE1 |\n",
    "| XIAP | Inhibitor of apoptosis protein 3 |\n",
    "\n",
    "</td><td>\n",
    "    \n",
    "| Name | Description |\n",
    "|-:|:-|\n",
    "| ACES | Acetylcholinesterase |\n",
    "| ADA | Adenosine deaminase |\n",
    "| ALDR | Aldose reductase |\n",
    "| AMPC | Beta-lactamase |\n",
    "| AOFB | Monoamine oxidase B |\n",
    "| CAH2 | Carbonic anhydrase II |\n",
    "| COMT | Catechol O-methyltransferase |\n",
    "| DEF | Peptide deformylase |\n",
    "| DHI1 | 11-beta-hydroxysteroid dehydrogenase 1 |\n",
    "| DYR | Dihydrofolate reductase |\n",
    "| FKB1A | FK506-binding protein 1A |\n",
    "| FNTA | Protein farnesyltransferase/geranylgeranyltransferase type I alpha subunit |\n",
    "| FPPS | Farnesyl diphosphate synthase |\n",
    "| GLCM | Beta-glucocerebrosidase |\n",
    "| HDAC2 | Histone deacetylase 2 |\n",
    "| HDAC8 | Histone deacetylase 8 |\n",
    "| HIVINT | Human immunodeficiency virus type 1 integrase |\n",
    "| HIVRT | Human immunodeficiency virus type 1 reverse transcriptase |\n",
    "| HMDH | HMG-CoA reductase |\n",
    "| HXK4 | Hexokinase type IV |\n",
    "| INHA | Enoyl-[acyl-carrier-protein] reductase |\n",
    "| KITH | Thymidine kinase |\n",
    "| NOS1 | Nitric-oxide synthase, brain |\n",
    "| NRAM | Neuraminidase |\n",
    "| PA2GA | Phospholipase A2 group IIA |\n",
    "| PARP1 | Poly [ADP-ribose] polymerase-1 |\n",
    "| PDE5A | Phosphodiesterase 5A |\n",
    "| PGH1 | Cyclooxygenase-1 |\n",
    "| PGH2 | Cyclooxygenase-2 |\n",
    "| PNPH | Purine nucleoside phosphorylase |\n",
    "| PTN1 | Protein-tyrosine phosphatase 1B |\n",
    "| PUR2 | GAR transformylase |\n",
    "| PYGM | Muscle glycogen phosphorylase |\n",
    "| PYRD | Dihydroorotate dehydrogenase |\n",
    "| SAHH | Adenosylhomocysteinase |\n",
    "| TYSY | Thymidylate synthase |\n",
    "    \n",
    "</td><td>\n",
    "\n",
    "| Name | Description |\n",
    "|-:|:-|\n",
    "| AA2AR | Adenosine A2a receptor |\n",
    "| ACE | Angiotensin-converting enzyme |\n",
    "| ADA17 | ADAM17 |\n",
    "| ADRB1 | Beta-1 adrenergic receptor |\n",
    "| ADRB2 | Beta-2 adrenergic receptor |\n",
    "| ANDR | Androgen Receptor |\n",
    "| BACE1 | Beta-secretase 1 |\n",
    "| CASP3 | Caspase-3 |\n",
    "| CP2C9 | Cytochrome P450 2C9 |\n",
    "| CP3A4 | Cytochrome P450 3A4 |\n",
    "| CXCR4 | C-X-C chemokine receptor type 4 |\n",
    "| DPP4 | Dipeptidyl peptidase IV |\n",
    "| DRD3 | Dopamine D3 receptor |\n",
    "| ESR1 | Estrogen receptor alpha |\n",
    "| ESR2 | Estrogen receptor beta |\n",
    "| FA10 | Coagulation factor X |\n",
    "| FA7 | Coagulation factor VII |\n",
    "| GCR | Glucocorticoid receptor |\n",
    "| HIVPR | Human immunodeficiency virus type 1 protease |\n",
    "| LKHA4 | Leukotriene A4 hydrolase |\n",
    "| MCR | Mineralocorticoid receptor |\n",
    "| MMP13 | Matrix metalloproteinase 13 |\n",
    "| PPARA | Peroxisome proliferator-activated receptor alpha |\n",
    "| PPARD | Peroxisome proliferator-activated receptor delta |\n",
    "| PPARG | Peroxisome proliferator-activated receptor gamma |\n",
    "| PRGR | Progesterone receptor |\n",
    "| RENI | Renin |\n",
    "| RXRA | Retinoid X receptor alpha |\n",
    "| THB | Thyroid hormone receptor beta-1 |\n",
    "| THRB | Thrombin |\n",
    "| TRY1 | Trypsin I |\n",
    "| TRYB1 | Tryptase beta-1 |\n",
    "| UROK | Urokinase-type plasminogen activator |\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "*The numbers*\n",
    "\n",
    "We use a 1:1 active-to-decoys ratio for training, and a 1:50 ratio for validation. In the single validation scheme, an 80:20 training-to-validation ratio is used for splitting each protein's ligand data between training and validation.\n",
    "\n",
    "| Fold | Actives | Decoys | Type |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| Single | 18204 | 18204 | Training |\n",
    "| Single | 4601 | 230050 | Validation |\n",
    "| CV 1 | 16392 | 16392 | Training |\n",
    "| CV 1 | 6413 | 320650 | Validation |\n",
    "| CV 2 | 16261 | 16261 | Training |\n",
    "| CV 2 | 6544 | 327200 | Validation |\n",
    "| CV 3 | 12957 | 12957 | Training |\n",
    "| CV 3 | 9848 | 492400 | Validation |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation comparison plots\n",
    "\n",
    "I've chosen to display training and validation performance on different subplots with a shared x-axis because of great differences in y-axis scale, and to avoid overloading the same plot with multiple lines (for different training/validation mode-`Fold` combinations).\n",
    "\n",
    "For the plot, I initially tried to use a Plotly Express line graph, but it doesn't seem to allow updating of the y-axis data. I've thus switched to using lower-level functions, which makes splitting data by fold more complex, and necessitates adding the traces of all metrics to the figure *before* plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivot_table(data, metric):\n",
    "    \"\"\"Return a table of `metric` values by fold from `data`.\"\"\"\n",
    "    return pd.pivot_table(data, values=metric, index=[\"Epoch\"], columns=\"Fold\")\n",
    "\n",
    "\n",
    "def get_hovertext(metric, fold, epoch):\n",
    "    \"\"\"Return `metric` performance at epoch `epoch` of fold `fold` as hovertext.\"\"\"\n",
    "    # Find the position of the metric value, if any.\n",
    "    text = f\"<b>{fold} epoch {epoch}</b><br>\"\n",
    "\n",
    "    training_index = np.where(\n",
    "        (all_train_perf.Epoch == epoch) & (all_train_perf.Fold == fold)\n",
    "    )[0]\n",
    "    if len(training_index) > 1:\n",
    "        raise Exception(\n",
    "            f\"Training duplicates exist for {metric} in {fold} for epoch {epoch}.\"\n",
    "        )\n",
    "    elif len(training_index) == 1:\n",
    "        text += f\"Training: {all_train_perf[metric][training_index[0]].item():.3f}<br>\"\n",
    "\n",
    "    # If the epoch is even-numbered, validation may have been conducted for it.\n",
    "    if epoch % 2 == 0:\n",
    "        validation_index = np.where(\n",
    "            (all_val_perf.Epoch == epoch) & (all_val_perf.Fold == fold)\n",
    "        )[0]\n",
    "        if len(validation_index) > 1:\n",
    "            raise Exception(\n",
    "                f\"Validation duplicates exist for {metric} in {fold} for epoch {epoch}.\"\n",
    "            )\n",
    "        elif len(validation_index) == 1:\n",
    "            text += f\"Validation: {all_val_perf[metric][validation_index[0]].item():.3f}<br>\"\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def add_traces(fig, row, col, showlegend, data, metric, visible):\n",
    "    \"\"\"Return the figure after adding the traces of `metric` performance.\"\"\"\n",
    "    curr_data = get_pivot_table(data, metric)\n",
    "    for fold in curr_data.columns:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=curr_data.index,\n",
    "                y=curr_data[fold].values,\n",
    "                name=fold,\n",
    "                mode=\"lines\",\n",
    "                line=dict(shape=\"linear\", color=FOLD_COLORS[fold]),\n",
    "                connectgaps=True,\n",
    "                # Show only the legend of validation plots to avoid duplication.\n",
    "                showlegend=showlegend,\n",
    "                # Initially, only plots displaying accuracy are visible.\n",
    "                visible=visible,\n",
    "                hovertext=[\n",
    "                    get_hovertext(metric, fold, epoch) for epoch in curr_data.index\n",
    "                ],\n",
    "                hoverinfo=\"text\",\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create facetted plot.\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.04,\n",
    "    row_titles=[\"Training\", \"Validation\"],\n",
    "    x_title=\"Epoch\",\n",
    "    y_title=\"Accuracy\",  # The initial displayed metric is accuracy.\n",
    ")\n",
    "\n",
    "# For each metric,\n",
    "for metric in TRAINING_RESULTS_HEADER[:-4]:\n",
    "    # add the training plots.\n",
    "    add_traces(fig, 1, 1, False, all_train_perf, metric, metric == \"Accuracy\")\n",
    "    # add the validation plots.\n",
    "    add_traces(fig, 2, 1, True, all_val_perf, metric, metric == \"Accuracy\")\n",
    "\n",
    "# Decouple the y-axes.\n",
    "fig.update_yaxes(matches=None, title=\"\")\n",
    "# Couple together x-axes and set ticks.\n",
    "fig.update_xaxes(\n",
    "    tickmode=\"array\",\n",
    "    tickvals=list(range(2, np.max(all_train_perf.Epoch) + 1, 2)),\n",
    ")\n",
    "\n",
    "# Add button to change y-axis data.\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"dropdown\",\n",
    "            direction=\"down\",\n",
    "            active=0,\n",
    "            showactive=True,\n",
    "            xanchor=\"left\",\n",
    "            yanchor=\"top\",\n",
    "            y=1.2,\n",
    "            x=1,\n",
    "            pad={\"r\": 10, \"t\": 10},\n",
    "            buttons=list(\n",
    "                [\n",
    "                    dict(\n",
    "                        label=metric,\n",
    "                        method=\"update\",\n",
    "                        args=[\n",
    "                            {\n",
    "                                \"visible\": [\n",
    "                                    k == i\n",
    "                                    for k in range(len(TRAINING_RESULTS_HEADER[:-4]))\n",
    "                                    for _ in range(7)\n",
    "                                ]\n",
    "                            },\n",
    "                            {\n",
    "                                \"y\": metric,\n",
    "                                # Allow a dynamic y-axis title depending on chosen metric,\n",
    "                                # while retaining fixed annotations.\n",
    "                                \"annotations\": [\n",
    "                                    {\n",
    "                                        \"font\": {\"size\": 16},\n",
    "                                        \"showarrow\": False,\n",
    "                                        \"text\": \"Training\",\n",
    "                                        \"textangle\": 90,\n",
    "                                        \"x\": 0.98,\n",
    "                                        \"xanchor\": \"left\",\n",
    "                                        \"xref\": \"paper\",\n",
    "                                        \"y\": 0.76,\n",
    "                                        \"yanchor\": \"middle\",\n",
    "                                        \"yref\": \"paper\",\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"font\": {\"size\": 16},\n",
    "                                        \"showarrow\": False,\n",
    "                                        \"text\": \"Validation\",\n",
    "                                        \"textangle\": 90,\n",
    "                                        \"x\": 0.98,\n",
    "                                        \"xanchor\": \"left\",\n",
    "                                        \"xref\": \"paper\",\n",
    "                                        \"y\": 0.24,\n",
    "                                        \"yanchor\": \"middle\",\n",
    "                                        \"yref\": \"paper\",\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"font\": {\"size\": 16},\n",
    "                                        \"showarrow\": False,\n",
    "                                        \"text\": \"Epoch\",\n",
    "                                        \"x\": 0.49,\n",
    "                                        \"xanchor\": \"center\",\n",
    "                                        \"xref\": \"paper\",\n",
    "                                        \"y\": 0,\n",
    "                                        \"yanchor\": \"top\",\n",
    "                                        \"yref\": \"paper\",\n",
    "                                        \"yshift\": -30,\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"font\": {\"size\": 16},\n",
    "                                        \"showarrow\": False,\n",
    "                                        \"text\": metric,\n",
    "                                        \"textangle\": -90,\n",
    "                                        \"x\": 0,\n",
    "                                        \"xanchor\": \"right\",\n",
    "                                        \"xref\": \"paper\",\n",
    "                                        \"xshift\": -40,\n",
    "                                        \"y\": 0.5,\n",
    "                                        \"yanchor\": \"middle\",\n",
    "                                        \"yref\": \"paper\",\n",
    "                                    },\n",
    "                                ],\n",
    "                            },\n",
    "                        ],\n",
    "                    )\n",
    "                    for i, metric in enumerate(TRAINING_RESULTS_HEADER[:-4])\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the training performance across folds and across metrics is near-perfect within 2-4 epochs. It is thus divorced from validation performance, particularly for `CV 3`, which has markedly worse precision than models trained under different folds. Moreover, we notice the following:\n",
    "\n",
    "1. Performance on `CV 3` in terms of the metrics it lags in - primarily precision and loss - show improvement towards the very last few epochs. We should train the model on more epochs and then re-validate it. This is in stark contrast to the model's performance in other folds, where it achieves peak (AUPR) performance within <10 epochs. (Note that in our meeting last week, the last two epoch's worth of validation data seem to have been cut off from the visualization due to a bug with my graphing implementation; thanks for asking me to re-plot things again in less of a rush.)\n",
    "2. Performance of the model on other folds, while generally better, is still quite unstable in terms of precision.\n",
    "3. As noted before, AUC is a poor metric for model performance because it does not reflect precision even indirectly, given the high active-to-decoys ratio.\n",
    "\n",
    "From both 1. and 2., we see that our learning procedure may have room for improvement: should we make the model more shallow? Should we use a different optimizer (we are currently using Adam with a small initial learning rate)? We need to stabilize learning and get it taking \"good learning directions\" consistently and in few epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotly includes the metric selection button when the image is exported. I couldn't find a way to hide it during export, and so have created the function below to export the plot for each specific metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to write training/validation plots to disk.\n",
    "\n",
    "\n",
    "def get_fig(metric):\n",
    "    fig = make_subplots(\n",
    "        rows=2,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.04,\n",
    "        row_titles=[\"Training\", \"Validation\"],\n",
    "        x_title=\"Epoch\",\n",
    "        y_title=metric,\n",
    "    )\n",
    "\n",
    "    # Add the training plots.\n",
    "    add_traces(fig, 1, 1, False, all_train_perf, metric, True)\n",
    "    # Add the validation plots.\n",
    "    add_traces(fig, 2, 1, True, all_val_perf, metric, True)\n",
    "\n",
    "    fig.update_yaxes(matches=None, title=\"\")\n",
    "    fig.update_xaxes(\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(2, np.max(all_train_perf.Epoch) + 1, 2)),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def write_static_image(metric, path):\n",
    "    \"\"\"Write training/validation plot for `metric` as static image.\"\"\"\n",
    "    get_fig(metric).write_image(path)\n",
    "\n",
    "\n",
    "def write_all_static_images(base_path, ext):\n",
    "    \"\"\"Write training/validation plot for all metrics as static images.\"\"\"\n",
    "    for metric in TRAINING_RESULTS_HEADER[:-4]:\n",
    "        write_static_image(metric, f\"{base_path}/{metric}.{ext}\")\n",
    "\n",
    "\n",
    "def write_html(metric, path):\n",
    "    \"\"\"Write training/validation plot for `metric` to HTML.\"\"\"\n",
    "    get_fig(metric).write_html(path, include_plotlyjs=\"cdn\")\n",
    "\n",
    "\n",
    "def write_all_htmls(base_path):\n",
    "    \"\"\"Write all training/validation plots to HTML.\"\"\"\n",
    "    for metric in TRAINING_RESULTS_HEADER[:-4]:\n",
    "        write_html(metric, f\"{base_path}/{metric}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_all_static_images(\"images\", \"pdf\")\n",
    "write_all_htmls(\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More details about the data and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ligand SMILES representation\n",
    "\n",
    "Ligands' SMILES sequences are encoded using a bi-directional LSTM. Here, we consider the sequences' lengths (simply, the number of characters in each SMILES sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get the lengths of SMILES sequences.\n",
    "\n",
    "\n",
    "def get_length(path):\n",
    "    \"\"\"Return lengths of ligands in file `path`.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return [len(line.split()[0]) for line in f.readlines()]\n",
    "\n",
    "\n",
    "def get_all_lengths(folder_path):\n",
    "    \"\"\"Return list with the folder's ligand sequence lengths.\"\"\"\n",
    "    return [\n",
    "        length\n",
    "        for file in listdir(folder_path)\n",
    "        for length in get_length(f\"{folder_path}/{file}\")\n",
    "        if file.endswith(\".ism\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actives_lengths = get_all_lengths(\"dude_data/actives\")\n",
    "decoys_lengths = get_all_lengths(\"dude_data/decoys\")\n",
    "\n",
    "actives_median = np.median(actives_lengths)\n",
    "decoys_median = np.median(decoys_lengths)\n",
    "\n",
    "x_axis_ticks = list(range(0, 200, 20)) + [\n",
    "    actives_median,\n",
    "    decoys_median,\n",
    "]\n",
    "x_axis_ticks.remove(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=actives_lengths,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"Actives\",\n",
    "        hovertemplate=\"Length: %{x}<br>Density: %{y}\",\n",
    "    ),\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=decoys_lengths,\n",
    "        histnorm=\"probability density\",\n",
    "        name=\"Decoys\",\n",
    "        hovertemplate=\"Length: %{x}<br>Density: %{y}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(\n",
    "    barmode=\"overlay\",\n",
    "    title=\"Ligand SMILES sequence lengths\",\n",
    "    xaxis=dict(\n",
    "        title=\"Sequence length\",\n",
    "        tickmode=\"array\",\n",
    "        tickvals=x_axis_ticks,\n",
    "    ),\n",
    "    yaxis=dict(title=\"Probability density\"),\n",
    "    # Mean lines\n",
    "    shapes=[\n",
    "        {\n",
    "            \"line\": {\"color\": qualitative.Plotly[0], \"dash\": \"solid\", \"width\": 3},\n",
    "            \"type\": \"line\",\n",
    "            \"x0\": actives_median,\n",
    "            \"x1\": actives_median,\n",
    "            \"xref\": \"x\",\n",
    "            \"y0\": -0.005,\n",
    "            \"y1\": 1,\n",
    "            \"yref\": \"paper\",\n",
    "        },\n",
    "        {\n",
    "            \"line\": {\"color\": qualitative.Plotly[1], \"dash\": \"solid\", \"width\": 3},\n",
    "            \"type\": \"line\",\n",
    "            \"x0\": decoys_median,\n",
    "            \"x1\": decoys_median,\n",
    "            \"xref\": \"x\",\n",
    "            \"y0\": -0.005,\n",
    "            \"y1\": 1,\n",
    "            \"yref\": \"paper\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Reduce opacity to see both histograms.\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the decoys associated with each active are chosen to have \"similar physico-chemical properties but dissimilar 2-D topology\" [(DUD-E website)](http://dude.docking.org/), the sequence lengths specifically are quite similar between the two groups, but with a few decoys being significantly larger than the rest.\n",
    "\n",
    "Moreover, within both groups, we see quite a large spread of lengths. While LSTMs can be effective in encoding long sequences, we should perhaps consider: how does sequence length relate to model performance? If the two are related significantly, what can we do to further improve performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protein contact map representation\n",
    "\n",
    "Proteins are represented using the contact map of their residues, and the contact map is processed using a 2D-CNN. The following is a distribution of the number of residues per protein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get the number of residues per protein.\n",
    "\n",
    "\n",
    "def get_length(path):\n",
    "    \"\"\"Return number of residues in file `path`.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return len(f.readlines()) - 2\n",
    "\n",
    "\n",
    "all_protein_lengths = [\n",
    "    get_length(f\"dude_data/contact_maps/{file}\")\n",
    "    for file in listdir(\"dude_data/contact_maps\")\n",
    "    if file.endswith(\"_full\")\n",
    "]\n",
    "\n",
    "num_residues_median = np.median(all_protein_lengths)\n",
    "x_axis_ticks = list(range(100, 900, 100)) + [num_residues_median]\n",
    "x_axis_ticks.remove(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=all_protein_lengths,\n",
    "        histnorm=\"probability density\",\n",
    "        hovertemplate=\"Residues: %{x}<br>Density: %{y}\",\n",
    "        nbinsx=40,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(\n",
    "    title=\"Number of residues per protein\",\n",
    "    xaxis=dict(\n",
    "        title=\"Number of residues\",\n",
    "        tickmode=\"array\",\n",
    "        tickvals=x_axis_ticks,\n",
    "    ),\n",
    "    yaxis=dict(title=\"Probability density\"),\n",
    "    # Mean lines\n",
    "    shapes=[\n",
    "        {\n",
    "            \"line\": {\"color\": \"black\", \"dash\": \"dash\", \"width\": 2},\n",
    "            \"type\": \"line\",\n",
    "            \"x0\": num_residues_median,\n",
    "            \"x1\": num_residues_median,\n",
    "            \"xref\": \"x\",\n",
    "            \"y0\": -0.005,\n",
    "            \"y1\": 1,\n",
    "            \"yref\": \"paper\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Reduce opacity to see both histograms.\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2D-CNN used to encode protein contact maps consists of eight stacked residual blocks and a sequential self-attention block:\n",
    "\n",
    "<img src=\"images/residual_block.png\" width=\"375\"/>\n",
    "\n",
    "Given contact maps can be of different sizes, the residual blocks do not enforce any dimensionality restrictions. Rather, after channelization through these blocks, the processed representation is pooled along each channel within the attention block to a fixed-size representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the diagnosis above, we need to consider:\n",
    "\n",
    "1. how does ligand sequence length relate to model performance?\n",
    "2. given training looks all-OK, how can we get more stable validation performance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
