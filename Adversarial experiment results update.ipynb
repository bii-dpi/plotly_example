{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objs as go, offline\n",
    "from plotly.express.colors import qualitative\n",
    "\n",
    "# Allow figures to work in HTML-exported version of notebook.\n",
    "offline.init_notebook_mode()\n",
    "\n",
    "prefixes = [f\"cv_{i}_\" for i in range(1, 4)] + [\"single_\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two updates\n",
    "\n",
    "12/05/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document discusses:\n",
    "    \n",
    "1. The pixelwise displacement and distance of our updater network's updates to its input.\n",
    "2. The performance of Mahsa's approach: verifying her performance by running her code, and by performing the attack on her trained model using *our* code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Distance and displacement of updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previous results**\n",
    "\n",
    "Recall that there are four \"configurations\" of our model:\n",
    "1. With an encoding network, and with z-score normalization of the input MNIST image.\n",
    "2. With encoding, and without z-score normalization.\n",
    "3. Without encoding, and with z-score normalization.\n",
    "4. Without encoding, and without z-score normalization.\n",
    "\n",
    "The original specification of the FGSM adversarial attack requires the input to be normalized to the 0-1 range for each pixel, and caps the perturbation of the input to keep it within this range.\n",
    "\n",
    "With our approach, we see that **only one configuration: configuration 2**, has appreciable robustness to the FGSM attack. Note that in attacks for configurations with z-score normalization, the perturbation is **not capped**, to stay consistent with the distribution of input pixel values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image.open(\"images/robustness.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds with the configuration that does the most updating, in terms of magnitude of pixel value change/distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"images/distance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, we see that the average distance each pixel is updated stabilizes quite quickly for all configurations. **Moreover, it seems that the configuration which leads to the most updating is most robust against attack; this is intuitive, since perhaps this tendency also helps \"undo\" the FGSM adversarial perturbations most effectively.**\n",
    "\n",
    "Let us look into this a little further, by considering how the average total *displacement* across pixels changes over updates and over epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total displacement over epochs**\n",
    "\n",
    "The purpose of considering average total pixelwise displacement, instead of just distance, is to verify that the updates aren't \"meandering\": that is, we want to consider whether the updater network is actually changing the value of pixels rather than frequently back-tracking on updates.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_diagnostic(enc, std):\n",
    "    enc_name = \"encoder\"\n",
    "    std_name = \"std\"\n",
    "    if not enc:\n",
    "        enc_name = \"no\" + enc_name\n",
    "    if not std:\n",
    "        std_name = \"no\" + std_name\n",
    "    curr_diagnostic = pd.read_csv(\n",
    "        f\"data/results/diagnostic_stats_{enc_name}_{std_name}_random_dense.csv\"\n",
    "    ).iloc[:, 1:]\n",
    "\n",
    "    curr_diagnostic = curr_diagnostic.groupby(\"epoch\")\n",
    "    curr_diagnostic = curr_diagnostic.mean()\n",
    "\n",
    "    config = \"\"\n",
    "    if enc:\n",
    "        config += \"Enc. & \"\n",
    "    else:\n",
    "        config += \"No enc. & \"\n",
    "    if std:\n",
    "        config += \"std.\"\n",
    "    else:\n",
    "        config += \"no std.\"\n",
    "    curr_diagnostic[\"Config.\"] = config\n",
    "\n",
    "    curr_diagnostic[\"Epoch\"] = list(range(1, curr_diagnostic.shape[0] + 1))\n",
    "    return curr_diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diagnostic = None\n",
    "for enc in [False, True]:\n",
    "    for std in [False, True]:\n",
    "        all_diagnostic = pd.concat(\n",
    "            [all_diagnostic, read_diagnostic(enc, std)], ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(all_diagnostic, x=\"Epoch\", y=\"mean_update_displacement\", color=\"Config.\")\n",
    "fig.update_yaxes(title=\"Mean update displacement\")\n",
    "fig.update_layout(\n",
    "    template=\"simple_white\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, x=0.15),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, all configurations are efficient in their updating: the magnitude of the displacement of each pixel is similar to the distance it is moved by. Efficiency in this regard therefore cannot help us diagnose the the configuration's robustness. At most, we see that inclusion of an encoder into the network has a generally negative effect on pixel values, that needs to be corrected to set pixels to their 0/1 class positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total displacement over updates**\n",
    "\n",
    "Recall that we give our updater network 50 iterations to update the input using the gradient of the network's output wrt the input, multiplied by a scaling factor of 0.1. Let us consider, for each of the configurations, the average cumulative displacement of each pixel over the 50 update iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mvmt(enc, std):\n",
    "    enc_name = \"encoder\"\n",
    "    std_name = \"std\"\n",
    "    if not enc:\n",
    "        enc_name = \"no\" + enc_name\n",
    "    if not std:\n",
    "        std_name = \"no\" + std_name\n",
    "    curr_mvmt = pd.read_csv(\n",
    "        f\"data/intra_mvmt/mvmt_{enc_name}_{std_name}_random_dense.csv\"\n",
    "    ).iloc[:, 1:]\n",
    "\n",
    "    config = \"\"\n",
    "    if enc:\n",
    "        config += \"Enc. & \"\n",
    "    else:\n",
    "        config += \"No enc. & \"\n",
    "    if std:\n",
    "        config += \"std.\"\n",
    "    else:\n",
    "        config += \"no std.\"\n",
    "    curr_mvmt[\"Config.\"] = config\n",
    "\n",
    "    curr_mvmt[\"Update iteration\"] = list(range(1, curr_mvmt.shape[0] + 1))\n",
    "    return curr_mvmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mvmt = None\n",
    "for enc in [False, True]:\n",
    "    for std in [False, True]:\n",
    "        all_mvmt = pd.concat([all_mvmt, read_mvmt(enc, std)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(all_mvmt, x=\"Update iteration\", y=\" Displacement\", color=\"Config.\")\n",
    "fig.update_yaxes(title=\"Mean total update displacement\")\n",
    "fig.update_layout(\n",
    "    template=\"simple_white\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, x=0.15),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to expectations, the updater networks from each configuration continue to update the input until the last iteration, albeit at different rates. On initial impression, this suggests that 50 updates may be insufficient: none of the configurations have learned to completely \"level out\" updating within 50 iterations.\n",
    "\n",
    "Let us thus consider models trained with a 200-update iteration allowance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mvmt_200(enc, std):\n",
    "    enc_name = \"encoder\"\n",
    "    std_name = \"std\"\n",
    "    if not enc:\n",
    "        enc_name = \"no\" + enc_name\n",
    "    if not std:\n",
    "        std_name = \"no\" + std_name\n",
    "    curr_mvmt = pd.read_csv(\n",
    "        f\"data/intra_mvmt/mvmt_{enc_name}_{std_name}_random_dense_200.csv\"\n",
    "    ).iloc[:, 1:]\n",
    "\n",
    "    config = \"\"\n",
    "    if enc:\n",
    "        config += \"Enc. & \"\n",
    "    else:\n",
    "        config += \"No enc. & \"\n",
    "    if std:\n",
    "        config += \"std.\"\n",
    "    else:\n",
    "        config += \"no std.\"\n",
    "    curr_mvmt[\"Config.\"] = config\n",
    "\n",
    "    curr_mvmt[\"Update iteration\"] = list(range(1, curr_mvmt.shape[0] + 1))\n",
    "    return curr_mvmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mvmt_200 = None\n",
    "for enc in [False, True]:\n",
    "    for std in [False, True]:\n",
    "        all_mvmt_200 = pd.concat(\n",
    "            [all_mvmt_200, read_mvmt_200(enc, std)], ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(all_mvmt_200, x=\"Update iteration\", y=\" Displacement\", color=\"Config.\")\n",
    "fig.update_yaxes(title=\"Mean total update displacement\")\n",
    "fig.update_layout(\n",
    "    template=\"simple_white\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, x=0.15),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we allow the model 200 update iterations:\n",
    "\n",
    "1. The configurations of the network without the encoder learn to change pixel values by about the same total amount, just more slowly. For them, it seems 50 updates were roughly sufficient.\n",
    "2. Configurations with the encoder continue to make approximately the same kinds of updates, leading to a significantly larger total after 200 update iterations.\n",
    "\n",
    "Despite these differences, the performance improvement of the model under each configuration is at least slightly worse than when they were allowed fewer updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_attack(enc, std, new):\n",
    "    enc_name = \"encoder\"\n",
    "    std_name = \"std\"\n",
    "    new_name = \"\" if not new else \"_200\"\n",
    "    if not enc:\n",
    "        enc_name = \"no\" + enc_name\n",
    "    if not std:\n",
    "        std_name = \"no\" + std_name\n",
    "    curr_results = pd.read_csv(\n",
    "        f\"data/results/robust_attack_results_{enc_name}_{std_name}_random_dense{new_name}.csv\"\n",
    "    ).iloc[:, 1:]\n",
    "\n",
    "    config = \"\"\n",
    "    if enc:\n",
    "        config += \"Enc. & \"\n",
    "    else:\n",
    "        config += \"No enc. & \"\n",
    "    if std:\n",
    "        config += \"std.\"\n",
    "    else:\n",
    "        config += \"no std.\"\n",
    "    curr_results[\"Config.\"] = config\n",
    "\n",
    "    return curr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_improvement(enc, std):\n",
    "    attack_200 = read_attack(enc, std, True)\n",
    "    attack_50 = read_attack(enc, std, False)\n",
    "    attack_200[\"Accuracy improvement\"] = attack_200.accuracy - attack_50.accuracy\n",
    "    attack_200[\"Epsilon\"] = attack_200.epsilon\n",
    "    return attack_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_improvement = None\n",
    "for enc in [False, True]:\n",
    "    for std in [False, True]:\n",
    "        all_improvement = pd.concat(\n",
    "            [all_improvement, read_improvement(enc, std)], ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(all_improvement, x=\"Epsilon\", y=\"Accuracy improvement\", color=\"Config.\")\n",
    "fig.update_layout(\n",
    "    template=\"simple_white\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, x=0.15),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reduction in performance under all configurations suggests our updater network training is ineffective.\n",
    "\n",
    "Specifically, the slightly worse performance of the 200-update model under our best configuration `Enc. & std.`, coupled with the fact that the model does not learn to level out updates within 200 epochs despite this worse performance, suggests that the training of our updater network is divorced from the model's robustness. This reinforces a statistic we discussed in the past: training MSE of our updater network under the `Enc. & std.` configuration is about 50 times greater than in configurations without encoders, even if the resulting model is far more robust.\n",
    "\n",
    "Moreover, there appear to be problems with the nature of the updater network surface itself: for the configurations with no encoder, we see that more (but smaller) updates result in significantly worse performance. Note that the zero accuracy improvement for greater values of the attack epsilon is due to the accuracy of both models - the original 50-update model and the new 200-update model - being zero under these attacks. Does the surface lack smoothness?\n",
    "\n",
    "**Given these issues, our primary question to answer is: how can we improve the training of our updater network?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Performance of Mahsa's approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we verify the results of Mahsa's approach.\n",
    "\n",
    "First, let us consider the performance of Mahsa's trained model using her `foolbox` library-based attack code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "robust_accuracy = [\n",
    "    1.0,\n",
    "    0.9979730414513023,\n",
    "    0.9960474308300395,\n",
    "    0.9936150805716023,\n",
    "    0.9916894699503395,\n",
    "    0.9887503800547279,\n",
    "    0.9857099422316814,\n",
    "    0.9820614168440256,\n",
    "    0.9767913246174116,\n",
    "    0.967670011148272,\n",
    "    0.951961082395865,\n",
    "    0.9294618425053207,\n",
    "    0.8923685010641532,\n",
    "    0.8224384311340833,\n",
    "    0.7124759298672343,\n",
    "]\n",
    "\n",
    "her_accuracy = [\n",
    "    1.0,\n",
    "    0.99,\n",
    "    0.985,\n",
    "    0.98,\n",
    "    0.975,\n",
    "    0.97,\n",
    "    0.965,\n",
    "    0.96,\n",
    "    0.94,\n",
    "    0.92,\n",
    "    0.90,\n",
    "    0.86,\n",
    "    0.805,\n",
    "    0.72,\n",
    "    0.63,\n",
    "]\n",
    "\n",
    "mahsa_df_orig = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"Attack epsilon\": np.round(np.arange(0.0, 0.75, 0.05), 2).tolist(),\n",
    "                \"Accuracy\": robust_accuracy,\n",
    "                \"Source\": \"Replicated results\",\n",
    "            }\n",
    "        ),\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"Attack epsilon\": np.round(np.arange(0.0, 0.75, 0.05), 2).tolist(),\n",
    "                \"Accuracy\": her_accuracy,\n",
    "                \"Source\": \"Paper results\",\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "fig = px.line(mahsa_df_orig, x=\"Attack epsilon\", y=\"Accuracy\", color=\"Source\")\n",
    "fig.update_layout(\n",
    "    template=\"simple_white\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, x=0.3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had access to a trained model under one configuration of hyperparameters (which used only her regularization), and the results under attack are reasonably similar to the reported results of the model under a similar set of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously stated, Mahsa z-score normalizes her inputs, which changes the range of each pixel from \\[0, 1\\] to ($-\\infty$, $\\infty$).\n",
    "\n",
    "However, her FGSM attack, implemented using the `foolbox` library, constrains the perturbed input's pixels within the \\[0, 1\\] bound.\n",
    "\n",
    "The following plot displays the performance of her model on an unconstrained attack: the same one executed on our best-performing `Enc. & std.` configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foolbox_acc = [\n",
    "    1.0,\n",
    "    0.9979730414513023,\n",
    "    0.9960474308300395,\n",
    "    0.9936150805716023,\n",
    "    0.9916894699503395,\n",
    "    0.9887503800547279,\n",
    "    0.9857099422316814,\n",
    "    0.9820614168440256,\n",
    "    0.9767913246174116,\n",
    "    0.967670011148272,\n",
    "    0.951961082395865,\n",
    "    0.9294618425053207,\n",
    "    0.8923685010641532,\n",
    "    0.8224384311340833,\n",
    "    0.7124759298672343,\n",
    "]\n",
    "\n",
    "manual_acc = [\n",
    "    0.990,\n",
    "    0.980,\n",
    "    0.969,\n",
    "    0.953,\n",
    "    0.938,\n",
    "    0.914,\n",
    "    0.883,\n",
    "    0.852,\n",
    "    0.806,\n",
    "    0.749,\n",
    "    0.679,\n",
    "    0.604,\n",
    "    0.517,\n",
    "    0.448,\n",
    "    0.374,\n",
    "]\n",
    "\n",
    "our_acc = [\n",
    "    0.986,\n",
    "    0.969,\n",
    "    0.925,\n",
    "    0.884,\n",
    "    0.818,\n",
    "    0.717,\n",
    "    0.606,\n",
    "    0.476,\n",
    "    0.375,\n",
    "    0.269,\n",
    "    0.180,\n",
    "    0.115,\n",
    "    0.082,\n",
    "    0.060,\n",
    "    0.043,\n",
    "]\n",
    "\n",
    "mahsa_df_orig = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"Attack epsilon\": np.round(np.arange(0.0, 0.75, 0.05), 2).tolist(),\n",
    "                \"Accuracy\": foolbox_acc,\n",
    "                \"Source\": \"Mahsa (constrained attack)\",\n",
    "            }\n",
    "        ),\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"Attack epsilon\": np.round(np.arange(0.0, 0.75, 0.05), 2).tolist(),\n",
    "                \"Accuracy\": manual_acc,\n",
    "                \"Source\": \"Mahsa (unconstrained attack)\",\n",
    "            },\n",
    "        ),\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"Attack epsilon\": np.round(np.arange(0.0, 0.75, 0.05), 2).tolist(),\n",
    "                \"Accuracy\": our_acc,\n",
    "                \"Source\": \"Updater network (enc. & std.)\",\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "fig = px.line(mahsa_df_orig, x=\"Attack epsilon\", y=\"Accuracy\", color=\"Source\")\n",
    "fig.update_layout(\n",
    "    template=\"simple_white\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, x=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that while removing the constraint on the perturbed input degrades performance somewhat, it is still far superior to our best configuration.\n",
    "\n",
    "Moreover, a key drawback of our model is its slow evaluation speed due to the update process; our model is about 40 times slower in evaluation than her's."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
